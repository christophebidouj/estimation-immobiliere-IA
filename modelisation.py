"""
=================================================================
MODÃ‰LISATION IA IMMOBILIÃˆRE - VERSION PÃ‰DAGOGIQUE POUR DÃ‰BUTANTS
=================================================================

Ce fichier montre comment crÃ©er un modÃ¨le d'IA pour estimer les prix immobiliers.
Objectif pÃ©dagogique : comprendre les Ã©tapes de base du Machine Learning.

Ã‰tapes principales :
1. Charger les donnÃ©es
2. Nettoyer les donnÃ©es  
3. CrÃ©er des variables (features)
4. EntraÃ®ner le modÃ¨le IA
5. Ã‰valuer les performances
6. Faire des prÃ©dictions
"""

import pandas as pd
import numpy as np
import joblib
import os
from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, VotingRegressor
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler, LabelEncoder
from sklearn.metrics import mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')

# Configuration simple
TAILLE_ECHANTILLON = 500_000  # Nombre de lignes Ã  utiliser
FICHIER_DONNEES = "data/valeurs_foncieres_nettoye/valeurs_foncieres_nettoye_2020_2024.csv"
DOSSIER_MODELES = "models"

def charger_donnees_immobilieres(fichier, taille_max):
    """
    Ã‰TAPE 1 : Charger les donnÃ©es immobiliÃ¨res
    
    Cette fonction lit un fichier CSV contenant des ventes immobiliÃ¨res
    et garde seulement les meilleures donnÃ©es pour l'IA.
    """
    print("ğŸ“ Chargement des donnÃ©es immobiliÃ¨res...")
    
    # Lire le fichier par petits morceaux (plus efficace)
    morceaux = []
    lignes_lues = 0
    
    for morceau in pd.read_csv(fichier, chunksize=100_000, low_memory=False):
        lignes_lues += len(morceau)
        morceaux.append(morceau)
        
        # ArrÃªter si on a assez de donnÃ©es
        if lignes_lues >= taille_max:
            break
    
    # Combiner tous les morceaux
    donnees = pd.concat(morceaux, ignore_index=True)
    print(f"âœ… {len(donnees):,} lignes chargÃ©es")
    
    return donnees

def nettoyer_donnees(donnees):
    """
    Ã‰TAPE 2 : Nettoyer les donnÃ©es
    
    On garde seulement les ventes avec toutes les informations nÃ©cessaires
    et on supprime les valeurs aberrantes (trop grandes ou trop petites).
    """
    print("ğŸ§¹ Nettoyage des donnÃ©es...")
    
    # Garde seulement les lignes avec les infos essentielles
    donnees_propres = donnees[
        donnees['Valeur fonciere'].notna() &           # Prix existe
        donnees['Surface reelle bati'].notna() &       # Surface existe  
        donnees['Nombre pieces principales'].notna()   # Nombre de piÃ¨ces existe
    ]
    
    # Supprime les valeurs aberrantes (prix et surface impossibles)
    donnees_propres = donnees_propres[
        (donnees_propres['Valeur fonciere'] >= 12_000) &        # Prix mini 12kâ‚¬
        (donnees_propres['Valeur fonciere'] <= 4_000_000) &     # Prix maxi 4Mâ‚¬
        (donnees_propres['Surface reelle bati'] >= 10) &        # Surface mini 10mÂ²
        (donnees_propres['Surface reelle bati'] <= 800) &       # Surface maxi 800mÂ²
        (donnees_propres['Nombre pieces principales'] >= 1) &   # Mini 1 piÃ¨ce
        (donnees_propres['Nombre pieces principales'] <= 15)    # Maxi 15 piÃ¨ces
    ]
    
    print(f"âœ… {len(donnees_propres):,} lignes aprÃ¨s nettoyage")
    return donnees_propres

def creer_variables_departement(donnees):
    """
    CrÃ©er la variable dÃ©partement Ã  partir du code postal
    Exemple : 75001 â†’ dÃ©partement 75 (Paris)
    """
    if 'Code postal corrigÃ©' in donnees.columns:
        donnees['dept'] = donnees['Code postal corrigÃ©'].astype(str).str[:2]
        
        # Garde seulement les dÃ©partements avec assez de donnÃ©es
        comptes_dept = donnees['dept'].value_counts()
        dept_frequents = comptes_dept[comptes_dept >= 100].index.tolist()
        donnees['dept'] = donnees['dept'].apply(
            lambda x: x if x in dept_frequents else 'autres'
        )
    else:
        donnees['dept'] = 'autres'
    
    return donnees

def creer_variables_temporelles(donnees):
    """
    CrÃ©er des variables sur les dates de vente
    L'IA peut apprendre si certaines pÃ©riodes ont des prix diffÃ©rents
    """
    if 'Date mutation' in donnees.columns:
        donnees['Date mutation'] = pd.to_datetime(donnees['Date mutation'], errors='coerce')
        donnees = donnees.dropna(subset=['Date mutation'])
        
        # Extraire l'annÃ©e et le mois
        donnees['annee'] = donnees['Date mutation'].dt.year
        donnees['mois'] = donnees['Date mutation'].dt.month
        
        # Variable "rÃ©cent" : 1 si vente aprÃ¨s 2023, 0 sinon
        donnees['recent'] = (donnees['annee'] >= 2023).astype(int)
        
        # CrÃ©er les saisons
        saisons = {12: 'hiver', 1: 'hiver', 2: 'hiver', 
                  3: 'printemps', 4: 'printemps', 5: 'printemps',
                  6: 'ete', 7: 'ete', 8: 'ete',
                  9: 'automne', 10: 'automne', 11: 'automne'}
        donnees['saison'] = donnees['mois'].map(saisons)
    else:
        # Valeurs par dÃ©faut si pas de date
        donnees['recent'] = 0
        donnees['saison'] = 'ete'
        donnees['annee'] = 2022
    
    return donnees

def creer_variables_ia(donnees):
    """
    Ã‰TAPE 3 : CrÃ©er les variables pour l'IA
    
    L'IA a besoin de variables numÃ©riques pour apprendre.
    On transforme nos donnÃ©es brutes en variables utiles.
    """
    print("ğŸ”§ CrÃ©ation des variables pour l'IA...")
    
    # Variables de base (directement du dataset)
    variables = pd.DataFrame({
        'surface': donnees['Surface reelle bati'],
        'pieces': donnees['Nombre pieces principales'],
    })
    
    # Ajouter le terrain si disponible
    if 'Surface terrain' in donnees.columns:
        variables['terrain'] = donnees['Surface terrain'].fillna(0)
        variables['avec_terrain'] = (variables['terrain'] > 50).astype(int)
    else:
        variables['terrain'] = 0
        variables['avec_terrain'] = 0
    
    # Variables calculÃ©es (l'IA apprend mieux avec ces transformations)
    variables['surface_par_piece'] = variables['surface'] / np.maximum(variables['pieces'], 1)
    variables['log_surface'] = np.log1p(variables['surface'])  # log(surface+1)
    variables['surface_x_pieces'] = variables['surface'] * variables['pieces']
    
    # Variables de catÃ©gorie (petite/moyenne/grande surface)
    variables['petit_logement'] = (variables['surface'] < 40).astype(int)
    variables['grand_logement'] = (variables['surface'] > 120).astype(int)
    
    # Ajouter les variables crÃ©Ã©es prÃ©cÃ©demment
    for col in ['dept', 'recent', 'saison', 'annee']:
        if col in donnees.columns:
            variables[col] = donnees[col]
    
    if 'Type local' in donnees.columns:
        variables['type_local'] = donnees['Type local'].fillna('Appartement')
    else:
        variables['type_local'] = 'Appartement'
    
    print(f"âœ… {len(variables.columns)} variables crÃ©Ã©es")
    return variables, donnees['Valeur fonciere']

def entrainer_modele_ia(X_train, y_train):
    """
    Ã‰TAPE 4 : EntraÃ®ner le modÃ¨le d'IA
    
    On utilise 3 algorithmes diffÃ©rents et on les combine :
    - Random Forest : trÃ¨s bon pour l'immobilier
    - Extra Trees : apporte de la diversitÃ©  
    - Ridge : Ã©vite le sur-apprentissage
    """
    print("ğŸ¤– EntraÃ®nement du modÃ¨le d'IA...")
    
    # Transformation logarithmique du prix (l'IA apprend mieux comme Ã§a)
    y_log = np.log1p(y_train)
    
    # Algorithme 1 : Random Forest (forÃªt alÃ©atoire)
    foret_aleatoire = RandomForestRegressor(
        n_estimators=100,        # Nombre d'arbres dans la forÃªt
        max_depth=20,           # Profondeur maximale des arbres
        min_samples_split=10,   # Minimum d'exemples pour diviser
        min_samples_leaf=5,     # Minimum d'exemples dans une feuille
        random_state=42,        # Pour reproduire les rÃ©sultats
        n_jobs=-1              # Utilise tous les processeurs
    )
    
    # Algorithme 2 : Extra Trees (arbres extra-alÃ©atoires)
    arbres_extra = ExtraTreesRegressor(
        n_estimators=80,
        max_depth=18,
        min_samples_split=12,
        random_state=43,
        n_jobs=-1
    )
    
    # Algorithme 3 : Ridge (rÃ©gression linÃ©aire rÃ©gularisÃ©e)
    regression_ridge = Ridge(alpha=75.0)
    
    # Combinaison des 3 algorithmes (ensemble)
    modele_combine = VotingRegressor([
        ('foret', foret_aleatoire),      # Poids 55%
        ('extra', arbres_extra),         # Poids 30% 
        ('ridge', regression_ridge)      # Poids 15%
    ], weights=[0.55, 0.3, 0.15])
    
    # EntraÃ®nement du modÃ¨le combinÃ©
    modele_combine.fit(X_train, y_log)
    
    print("âœ… ModÃ¨le d'IA entraÃ®nÃ©")
    return modele_combine

def evaluer_modele(modele, X_train, X_test, y_train, y_test):
    """
    Ã‰TAPE 5 : Ã‰valuer les performances du modÃ¨le
    
    On mesure si le modÃ¨le fait de bonnes prÃ©dictions avec des mÃ©triques :
    - RÂ² : qualitÃ© globale (0 = mauvais, 1 = parfait)
    - MAE : erreur moyenne en euros
    """
    print("ğŸ“Š Ã‰valuation des performances...")
    
    # PrÃ©dictions sur les donnÃ©es d'entraÃ®nement et de test
    y_pred_log_train = modele.predict(X_train)
    y_pred_log_test = modele.predict(X_test)
    
    # Retransformation vers les prix rÃ©els
    y_pred_train = np.expm1(y_pred_log_train)
    y_pred_test = np.expm1(y_pred_log_test)
    
    # Correction du biais (le modÃ¨le sous-estime souvent)
    facteur_correction = np.mean(y_train) / np.mean(y_pred_train)
    facteur_correction = max(0.5, min(2.0, facteur_correction))  # Limite sÃ©curitÃ©
    
    y_pred_train_corrige = y_pred_train * facteur_correction
    y_pred_test_corrige = y_pred_test * facteur_correction
    
    # Calcul des mÃ©triques
    r2_train = r2_score(y_train, y_pred_train_corrige)
    r2_test = r2_score(y_test, y_pred_test_corrige)
    mae_train = mean_absolute_error(y_train, y_pred_train_corrige)
    mae_test = mean_absolute_error(y_test, y_pred_test_corrige)
    
    # Mesure du sur-apprentissage
    suraprentissage = abs(r2_train - r2_test)
    
    # Affichage des rÃ©sultats
    print(f"\nğŸ† RÃ‰SULTATS DU MODÃˆLE :")
    print(f"ğŸ“ˆ RÂ² (qualitÃ©) : {r2_test:.3f} (plus proche de 1 = mieux)")
    print(f"ğŸ’° Erreur moyenne : {mae_test:,.0f}â‚¬")
    print(f"ğŸ¯ Sur-apprentissage : {suraprentissage:.3f} (plus petit = mieux)")
    
    # InterprÃ©tation des rÃ©sultats
    if r2_test > 0.35:
        print("âœ… TrÃ¨s bon modÃ¨le !")
    elif r2_test > 0.25:
        print("âœ… Bon modÃ¨le")
    else:
        print("âš ï¸ ModÃ¨le Ã  amÃ©liorer")
    
    return {
        'r2_test': r2_test,
        'mae_test': mae_test,
        'facteur_correction': facteur_correction,
        'suraprentissage': suraprentissage
    }

def sauvegarder_modele(modele, encodeurs, normaliseur, colonnes, resultats):
    """
    Sauvegarder le modÃ¨le entraÃ®nÃ© pour l'utiliser plus tard
    """
    print("ğŸ’¾ Sauvegarde du modÃ¨le...")
    
    os.makedirs(DOSSIER_MODELES, exist_ok=True)
    
    # Sauvegarde des composants
    joblib.dump(modele, f'{DOSSIER_MODELES}/modele_ia.pkl')
    joblib.dump(encodeurs, f'{DOSSIER_MODELES}/encodeurs.pkl')
    joblib.dump(normaliseur, f'{DOSSIER_MODELES}/normaliseur.pkl')
    joblib.dump(colonnes, f'{DOSSIER_MODELES}/colonnes.pkl')
    
    # MÃ©tadonnÃ©es
    infos_modele = {
        'performance': resultats,
        'description': 'ModÃ¨le IA simplifiÃ© pour dÃ©butants',
        'facteur_correction': resultats['facteur_correction']
    }
    joblib.dump(infos_modele, f'{DOSSIER_MODELES}/infos_modele.pkl')
    
    print("âœ… ModÃ¨le sauvegardÃ© avec succÃ¨s !")

def estimer_prix_immobilier(surface, pieces, dept='75', terrain=0, type_local='Appartement', recent=1):
    """
    Ã‰TAPE 6 : Faire une prÃ©diction avec le modÃ¨le entraÃ®nÃ©
    
    Cette fonction utilise le modÃ¨le sauvegardÃ© pour estimer le prix
    d'un bien immobilier selon ses caractÃ©ristiques.
    """
    try:
        # Chargement du modÃ¨le et de ses composants
        modele = joblib.load(f'{DOSSIER_MODELES}/modele_ia.pkl')
        encodeurs = joblib.load(f'{DOSSIER_MODELES}/encodeurs.pkl')
        normaliseur = joblib.load(f'{DOSSIER_MODELES}/normaliseur.pkl')
        colonnes = joblib.load(f'{DOSSIER_MODELES}/colonnes.pkl')
        infos = joblib.load(f'{DOSSIER_MODELES}/infos_modele.pkl')
        
        print(f"ğŸ  Estimation pour : {surface}mÂ², {pieces} piÃ¨ces, dept {dept}")
        
        # CrÃ©ation du vecteur de caractÃ©ristiques
        donnees_bien = {
            'surface': surface,
            'pieces': pieces,
            'terrain': terrain,
            'avec_terrain': 1 if terrain > 50 else 0,
            'surface_par_piece': surface / max(pieces, 1),
            'log_surface': np.log1p(surface),
            'surface_x_pieces': surface * pieces,
            'petit_logement': 1 if surface < 40 else 0,
            'grand_logement': 1 if surface > 120 else 0,
            'dept': dept,
            'recent': recent,
            'saison': 'ete',
            'annee': 2024,
            'type_local': type_local
        }
        
        # Conversion en DataFrame
        df_bien = pd.DataFrame([donnees_bien])
        
        # Encodage des variables catÃ©gorielles (texte â†’ chiffres)
        for colonne in ['dept', 'type_local', 'saison']:
            if colonne in encodeurs:
                encodeur = encodeurs[colonne]
                valeur = df_bien[colonne].iloc[0]
                try:
                    if hasattr(encodeur, 'classes_') and valeur in encodeur.classes_:
                        df_bien[colonne] = encodeur.transform([valeur])[0]
                    else:
                        df_bien[colonne] = 0
                except:
                    df_bien[colonne] = 0
        
        # Ajout des colonnes manquantes
        for col in colonnes:
            if col not in df_bien.columns:
                df_bien[col] = 0
        
        # RÃ©organisation des colonnes dans le bon ordre
        df_final = df_bien[colonnes]
        
        # Normalisation des donnÃ©es
        df_normalise = normaliseur.transform(df_final)
        
        # PrÃ©diction
        prediction_log = modele.predict(df_normalise)[0]
        prix_brut = np.expm1(prediction_log)
        
        # Application de la correction
        facteur_correction = infos['facteur_correction']
        prix_final = prix_brut * facteur_correction
        
        # VÃ©rification de cohÃ©rence avec les prix du marchÃ©
        prix_final = verifier_coherence_prix(prix_final, surface, dept, type_local, terrain)
        
        print(f"ğŸ’° Prix estimÃ© : {prix_final:,.0f}â‚¬")
        print(f"ğŸ“ Prix au mÂ² : {prix_final/surface:,.0f}â‚¬/mÂ²")
        
        return prix_final
        
    except FileNotFoundError:
        print("âŒ ModÃ¨le non trouvÃ©. EntraÃ®nez d'abord le modÃ¨le.")
        return None
    except Exception as e:
        print(f"âŒ Erreur : {e}")
        return None

def verifier_coherence_prix(prix, surface, dept, type_local, terrain):
    """
    VÃ©rification de cohÃ©rence pour Ã©viter les prix aberrants
    """
    # Prix de rÃ©fÃ©rence par mÂ² selon la rÃ©gion
    prix_reference_m2 = {
        '75': 9200,   # Paris
        '92': 6500,   # Hauts-de-Seine
        '13': 3500,   # Marseille
        '69': 4200,   # Lyon
        '33': 3800,   # Bordeaux
    }
    
    prix_m2_ref = prix_reference_m2.get(dept, 3000)  # 3000â‚¬/mÂ² par dÃ©faut
    prix_attendu = prix_m2_ref * surface
    
    # Ajustements selon le type
    if type_local == 'Maison':
        prix_attendu *= 1.05  # +5% pour les maisons
    if terrain > 200:
        prix_attendu *= 1.1   # +10% pour grand terrain
    
    # Si le prix est trop diffÃ©rent, on ajuste
    ratio = prix / prix_attendu
    if ratio > 2.0:  # Trop cher
        prix_corrige = prix * 0.4 + prix_attendu * 0.6
    elif ratio < 0.5:  # Trop bon marchÃ©
        prix_corrige = prix * 0.6 + prix_attendu * 0.4
    else:
        prix_corrige = prix
    
    return prix_corrige

def entrainer_modele_complet():
    """
    PIPELINE COMPLET : Toutes les Ã©tapes d'entraÃ®nement du modÃ¨le IA
    """
    print("ğŸš€ ENTRAÃNEMENT COMPLET DU MODÃˆLE IA")
    print("=" * 50)
    
    try:
        # Ã‰tape 1 : Charger les donnÃ©es
        donnees_brutes = charger_donnees_immobilieres(FICHIER_DONNEES, TAILLE_ECHANTILLON)
        
        # Ã‰tape 2 : Nettoyer les donnÃ©es
        donnees_propres = nettoyer_donnees(donnees_brutes)
        donnees_propres = creer_variables_departement(donnees_propres)
        donnees_propres = creer_variables_temporelles(donnees_propres)
        
        # Ã‰tape 3 : CrÃ©er les variables pour l'IA
        X, y = creer_variables_ia(donnees_propres)
        
        print(f"ğŸ“Š Dataset final : {len(X):,} lignes, {len(X.columns)} variables")
        print(f"ğŸ’° Prix : de {y.min():,.0f}â‚¬ Ã  {y.max():,.0f}â‚¬")
        
        # Division train/test (80% entraÃ®nement, 20% test)
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Encodage des variables catÃ©gorielles
        X_train_encode = X_train.copy()
        X_test_encode = X_test.copy()
        encodeurs = {}
        
        colonnes_texte = X_train_encode.select_dtypes(include=['object']).columns
        for col in colonnes_texte:
            encodeur = LabelEncoder()
            X_train_encode[col] = encodeur.fit_transform(X_train_encode[col].astype(str))
            
            # Encoder le test en gÃ©rant les nouvelles valeurs
            valeurs_test = X_test_encode[col].astype(str)
            valeurs_encodees = []
            for val in valeurs_test:
                try:
                    valeurs_encodees.append(encodeur.transform([val])[0])
                except:
                    valeurs_encodees.append(0)  # Valeur par dÃ©faut
            X_test_encode[col] = valeurs_encodees
            encodeurs[col] = encodeur
        
        # Normalisation des donnÃ©es
        normaliseur = RobustScaler()
        X_train_normalise = normaliseur.fit_transform(X_train_encode)
        X_test_normalise = normaliseur.transform(X_test_encode)
        
        # Conversion en DataFrame
        X_train_final = pd.DataFrame(X_train_normalise, columns=X_train_encode.columns)
        X_test_final = pd.DataFrame(X_test_normalise, columns=X_train_encode.columns)
        
        # Ã‰tape 4 : EntraÃ®ner le modÃ¨le
        modele = entrainer_modele_ia(X_train_final, y_train)
        
        # Ã‰tape 5 : Ã‰valuer les performances
        resultats = evaluer_modele(modele, X_train_final, X_test_final, y_train, y_test)
        
        # Ã‰tape 6 : Sauvegarder si satisfaisant
        if resultats['r2_test'] > 0.25:  # Seuil minimum
            sauvegarder_modele(modele, encodeurs, normaliseur, X_train_final.columns.tolist(), resultats)
            print("\nğŸ‰ MODÃˆLE ENTRAÃNÃ‰ AVEC SUCCÃˆS !")
            return True
        else:
            print("\nâš ï¸ Performances insuffisantes, modÃ¨le non sauvegardÃ©")
            return False
            
    except Exception as e:
        print(f"âŒ Erreur pendant l'entraÃ®nement : {e}")
        return False

def tester_modele():
    """
    Tester le modÃ¨le avec quelques exemples
    """
    print("\nğŸ§ª TESTS DU MODÃˆLE")
    print("=" * 30)
    
    exemples = [
        {"desc": "Studio parisien", "params": {"surface": 25, "pieces": 1, "dept": "75"}},
        {"desc": "Appartement parisien", "params": {"surface": 60, "pieces": 3, "dept": "75"}},
        {"desc": "Maison banlieue", "params": {"surface": 120, "pieces": 5, "dept": "92", "terrain": 300, "type_local": "Maison"}},
        {"desc": "Appartement Lyon", "params": {"surface": 75, "pieces": 3, "dept": "69"}},
    ]
    
    for exemple in exemples:
        print(f"\nğŸ“ {exemple['desc']} :")
        prix = estimer_prix_immobilier(**exemple['params'])
        if prix:
            surface = exemple['params']['surface']
            print(f"   ğŸ“Š {prix/surface:,.0f}â‚¬/mÂ²")

if __name__ == "__main__":
    print("ğŸ  MODÃˆLE IA IMMOBILIER - VERSION PÃ‰DAGOGIQUE")
    print("=" * 55)
    print("ğŸ“š Ce code montre les bases du Machine Learning appliquÃ© Ã  l'immobilier")
    print()
    
    # EntraÃ®nement du modÃ¨le
    succes = entrainer_modele_complet()
    
    # Test si l'entraÃ®nement a rÃ©ussi
    if succes:
        tester_modele()
    
    print("\nğŸ’¡ Pour utiliser ce modÃ¨le dans Streamlit, lancez app.py")